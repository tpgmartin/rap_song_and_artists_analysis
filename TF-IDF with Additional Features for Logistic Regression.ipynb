{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF with Additional Features for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracks_by_artist = pd.read_csv(\"./data/tracks_with_lyrics_for_top_10_artists.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>track</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T.I.</td>\n",
       "      <td>Trap Muzik</td>\n",
       "      <td>I Can't Quit</td>\n",
       "      <td>[Intro]\\nHuh, hell nah, I can't quit\\nHell nah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T.I.</td>\n",
       "      <td>Trap Muzik</td>\n",
       "      <td>Be Easy</td>\n",
       "      <td>[Intro]\\nUh-uh, uh-uh, uh\\nAye, where the pian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T.I.</td>\n",
       "      <td>Trap Muzik</td>\n",
       "      <td>No More Talk</td>\n",
       "      <td>[Verse 1]\\nI'm either running for my life or I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T.I.</td>\n",
       "      <td>Trap Muzik</td>\n",
       "      <td>Doin My Job</td>\n",
       "      <td>[T.I. - talking]\\nAy I'm working here, know wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T.I.</td>\n",
       "      <td>Trap Muzik</td>\n",
       "      <td>24's</td>\n",
       "      <td>[Intro]\\nYeah\\nFor all my real ATL niggas, tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist       album         track  \\\n",
       "0   T.I.  Trap Muzik  I Can't Quit   \n",
       "1   T.I.  Trap Muzik       Be Easy   \n",
       "2   T.I.  Trap Muzik  No More Talk   \n",
       "3   T.I.  Trap Muzik   Doin My Job   \n",
       "4   T.I.  Trap Muzik          24's   \n",
       "\n",
       "                                              lyrics  \n",
       "0  [Intro]\\nHuh, hell nah, I can't quit\\nHell nah...  \n",
       "1  [Intro]\\nUh-uh, uh-uh, uh\\nAye, where the pian...  \n",
       "2  [Verse 1]\\nI'm either running for my life or I...  \n",
       "3  [T.I. - talking]\\nAy I'm working here, know wh...  \n",
       "4  [Intro]\\nYeah\\nFor all my real ATL niggas, tha...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_by_artist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>track</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>Tech N9ne</td>\n",
       "      <td>Everready (The Religion)</td>\n",
       "      <td>The Melancholy Maze &amp; My World Intro</td>\n",
       "      <td>[Intro]\\nYou have entered The Melancholy Maze\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>Tech N9ne</td>\n",
       "      <td>Everready (The Religion)</td>\n",
       "      <td>The Beast</td>\n",
       "      <td>[Intro 1: Krizz Kaliko]\\nInsanity at it's fine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>Tech N9ne</td>\n",
       "      <td>Everready (The Religion)</td>\n",
       "      <td>Intro to the Strange Music Library</td>\n",
       "      <td>[Tech N9ne]\\nYo, what's up?\\nTech N9ne here\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>Tech N9ne</td>\n",
       "      <td>Everready (The Religion)</td>\n",
       "      <td>That Owl</td>\n",
       "      <td>[Verse 1]\\nHe wild out his style 'bout a mile ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>Tech N9ne</td>\n",
       "      <td>Everready (The Religion)</td>\n",
       "      <td>In My Head</td>\n",
       "      <td>First entry to Everready: The Religion\\nIt's c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        artist                     album  \\\n",
       "751  Tech N9ne  Everready (The Religion)   \n",
       "752  Tech N9ne  Everready (The Religion)   \n",
       "753  Tech N9ne  Everready (The Religion)   \n",
       "754  Tech N9ne  Everready (The Religion)   \n",
       "755  Tech N9ne  Everready (The Religion)   \n",
       "\n",
       "                                    track  \\\n",
       "751  The Melancholy Maze & My World Intro   \n",
       "752                             The Beast   \n",
       "753    Intro to the Strange Music Library   \n",
       "754                              That Owl   \n",
       "755                            In My Head   \n",
       "\n",
       "                                                lyrics  \n",
       "751  [Intro]\\nYou have entered The Melancholy Maze\\...  \n",
       "752  [Intro 1: Krizz Kaliko]\\nInsanity at it's fine...  \n",
       "753  [Tech N9ne]\\nYo, what's up?\\nTech N9ne here\\nA...  \n",
       "754  [Verse 1]\\nHe wild out his style 'bout a mile ...  \n",
       "755  First entry to Everready: The Religion\\nIt's c...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_by_artist = tracks_by_artist[~tracks_by_artist[\"lyrics\"].isnull()]\n",
    "tracks_by_artist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def tokenizer(raw_lyrics):\n",
    "    # Some choices here are specific to the format of Genius lyrics, want to remove non-vocalised \n",
    "    # text in square brackets, and other text not part of the main song body such as adlibs in \n",
    "    # round brackets\n",
    "    raw_lyrics = re.sub(\"([\\(\\[].*?[\\)\\]])|([^\\w\\d'\\s]+)\", \"\", raw_lyrics)\n",
    "    raw_lyrics = re.sub(\"\\n\", \" \", raw_lyrics)\n",
    "    # Ignore case    \n",
    "    raw_lyrics = raw_lyrics.lower()\n",
    "    word_list = raw_lyrics.split()\n",
    "\n",
    "    return word_list\n",
    "\n",
    "def normalise_vector(vector):\n",
    "    return vector / np.sqrt(np.dot(vector,vector))\n",
    "\n",
    "def add_vectors(vectors):\n",
    "    return normalise_vector(np.sum(vectors, axis=0))\n",
    "\n",
    "def ranked_words_by_weighting(vector, top_n):\n",
    "    return sorted(zip(vectorizer.get_feature_names(), vector), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "def most_representative_songs(vector, tracks_by_artist, top_n):\n",
    "    df = tracks_by_artist.copy()\n",
    "    df[\"dist\"] = df[\"normalised_vectors\"].apply(lambda target: cosine(vector, target))\n",
    "    df.sort_values(\"dist\", inplace=True)\n",
    "    return df[:top_n]\n",
    "\n",
    "def most_similar_artists(vector, artist_vectors, top_n):\n",
    "    df = artist_vectors.reset_index().copy()\n",
    "    df[\"dist\"] = df[\"normalised_vectors\"].apply(lambda target: cosine(vector, target))\n",
    "    df.sort_values(\"dist\", inplace=True)\n",
    "    return df[1:top_n+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ignore for time being\n",
    "# hyperparamters = [\n",
    "#     {\"max_df\": 1.0, \"min_df\": 1}, # i.e. default values\n",
    "#     {\"max_df\": 1.0, \"min_df\": 0.001},\n",
    "#     {\"max_df\": 0.7, \"min_df\": 1},\n",
    "#     {\"max_df\": 0.7, \"min_df\": 0.001}\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for hp in hyperparamters:\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=ENGLISH_STOP_WORDS,\n",
    "    max_df=0.7,\n",
    "    min_df=5,\n",
    "#     tokenizer=tokenizer,\n",
    "#     norm=None\n",
    ")\n",
    "\n",
    "tracks_by_artist_copy = tracks_by_artist.copy()\n",
    "tracks_by_artist_copy[\"unnormalised_vectors\"] = list(vectorizer.fit_transform(tracks_by_artist_copy[\"lyrics\"].values).toarray())\n",
    "tracks_by_artist_copy[\"normalised_vectors\"] = tracks_by_artist_copy[\"unnormalised_vectors\"].apply(normalise_vector)\n",
    "tracks_by_artist_copy = tracks_by_artist_copy[tracks_by_artist_copy[\"unnormalised_vectors\"].apply(sum) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(tracks_by_artist_copy, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3695"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train, X_train = train[\"artist\"].values.tolist(), train[\"normalised_vectors\"].values.tolist()\n",
    "y_test, X_test = test[\"artist\"].values.tolist(), test[\"normalised_vectors\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '[Intro]\\nYeah\\nYeah, yeah, yeah, yeah, yeah, yeah\\nOkay\\nAlright, a\\'ight, a\\'ight, a\\'ight, a\\'ight\\nYo, yo\\nAlright, I\\'mma lay the chorus first\\nHere we go now\\n\\n[Chorus]\\nMy mom loved Valium and lots of drugs\\nThat\\'s why I am like I am \\'cause I\\'m like her\\nBecause my mom loved Valium and lots of drugs\\nThat\\'s why I\\'m on what I\\'m on \\'cause I\\'m my mom\\n\\n[Verse 1]\\nMy mom, my mom, I know you\\'re probably tired\\nOf hearing \\'bout my mom, oh-ho, whoa-ho\\nBut this is just a story of when I was just a shorty\\nAnd how I became hooked on Va-aliu-um\\nValium was in everything, food that I ate\\nThe water that I drank, fuckin\\' peas on my plate\\nShe sprinkled just enough of it to season my steak\\nSo every day I\\'d have at least three stomachaches\\nNow tell me, what kind of mother would want to see her\\nSon grow up to be an undera-fuckin\\'-chiever?\\nMy teacher didn\\'t think I was gonna be nothin\\' either\\n\"What the fuck you stickin\\' gum up under the fucking seat for?\"\\n\"Mrs. Mathers, your son has been huffing ether\\nEither that or the motherfucker\\'s been puffin\\' reefer\"\\nBut all this huffin\\' and puffin\\' wasn\\'t what it was either\\nIt was neither, I was buzzing but it wasn\\'t what she thought\\nPee in a teacup? Bitch, you ain\\'t my keeper, I\\'m sleeping\\nWhat the fuck you keep on fucking with me for?\\nSlut, you need to leave me the fuck alone, I ain\\'t playin\\'\\nGo find you a white crayon and color a fucking zebra\\n\\n[Chorus]\\nMy mom loved Valium and lots of drugs\\nThat\\'s why I am like I am \\'cause I\\'m like her\\nBecause my mom loved Valium and lots of drugs\\nThat\\'s why I\\'m on what I\\'m on \\'cause I\\'m my mom\\n\\n[Verse 2]\\nWait a minute, this ain\\'t dinner, this is paint thinner\\n\"You ate it yesterday, I ain\\'t hear no complaints, did I?\\nNow here\\'s a plate full of painkillers\\nNow just wait \\'til I crush the Valium and put it in your potatoes\\nYou little motherfucker, I\\'ll make you sit there and make\\nThat retarded fucking face without even tasting it\\nYou better lick the fucking plate, you ain\\'t wasting it\\nPut your face in it \\'fore I throw you in the basement again\\nAnd I ain\\'t givin\\' in, you\\'re gonna just sit there\\nIn one fucking place, finnickin\\' \\'til next Thanksgiving\\nAnd if you still ain\\'t finished it I\\'ll use the same shit again\\nThen when I make spinach dip it\\'ll be placed in the shit\\nYou little shit, wanna sit there and play innocent?\\nA rack fell and hit me in K-Mart and they witnessed it\\nChild support, your father, he ain\\'t sent the shit\\nAnd so what if he did? It\\'s none of your dang business, kid\"\\n\\n[Bridge 1]\\nMy mom\\nThere\\'s no one else quite like my mom\\nI know I should let bygones be bygones\\nBut she\\'s the reason why I am high what I\\'m high on\\n\\n[Chorus]\\n\\'Cause my mom loved Valium and lots of drugs\\nThat\\'s why I am like I am \\'cause I\\'m like her\\nBecause my mom loved Valium and lots of drugs\\nThat\\'s why I\\'m on what I\\'m on \\'cause I\\'m my mom\\n\\n[Bridge 2]\\nMy mom loved Valium, now all I am\\nIs a party animal, I am what I am\\nBut I\\'m strong to the finish with me Valium spinach\\nBut my buzz only lasts about two minutes\\nBut I don\\'t wanna swallow it without chewin\\' it\\nI can\\'t even write a rhyme without you in it\\nMy Valium, my Vaaaaaa-liummmm, ohh\\n\\n[Verse 3]\\nMan, I never thought that I could ever be\\nA drug addict, naw, fuck that, I can\\'t have it happen to me\\nBut that\\'s actually what has ended up happening\\nA tragedy, the fucking past ended up catching me\\nAnd it\\'s probably where I got acquainted with the taste, ain\\'t it?\\nPharmaceuticals are the bomb, Mom, beautiful\\nShe killed the fuckin\\' dog with the medicine she done fed it\\nFeed it a fuckin\\' aspirin and say that it has a headache\\n\"Here, want a snack? You hungry, you fuckin\\' brat?\\nLook at that, it\\'s a Xanax, take it and take a nap, eat it\"\\nBut I don\\'t need it \"Well fuck it then, break it up\\nTake a little piece and beat it before you wake Nathan up\"\\nAlright Ma, you win, I don\\'t feel like arguin\\'\\nI\\'ll do it, pop and gobble it and start wobblin\\'\\nStumble, hobble, tumble, slip, trip, then I fall in bed\\nWith a bottle of meds and a Heath Ledger bobblehead\\n\\n[Chorus]\\nMy mom loved Valium and lots of drugs\\nThat\\'s why I am like I am \\'cause I\\'m like her\\nBecause my mom loved Valium and lots of drugs\\nThat\\'s why I\\'m on what I\\'m on \\'cause I\\'m my mom\\n\\n[Outro]\\nMy mom, I\\'m just like her\\nMy mom, my mom, my mom\\nMy mom, my mom, my mom\\nMy mom, my mom, my mom\\nMy mom, my momma\\nMe momma, I like-a da momma\\nHaha, sorry Mom\\nI still love you though\\nDr. Dre, 2010\\nAy, this shit is hella hard, homie\\nYo, take us on outta here\\nWoo!'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-a8f9a7fecf8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlogreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0;32m-> 1220\u001b[0;31m                          order=\"C\")\n\u001b[0m\u001b[1;32m   1221\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                       force_all_finite)\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '[Intro]\\nYeah\\nYeah, yeah, yeah, yeah, yeah, yeah\\nOkay\\nAlright, a\\'ight, a\\'ight, a\\'ight, a\\'ight\\nYo, yo\\nAlright, I\\'mma lay the chorus first\\nHere we go now\\n\\n[Chorus]\\nMy mom loved Valium and lots of drugs\\nThat\\'s why I am like I am \\'cause I\\'m like her\\nBecause my mom loved Valium and lots of drugs\\nThat\\'s why I\\'m on what I\\'m on \\'cause I\\'m my mom\\n\\n[Verse 1]\\nMy mom, my mom, I know you\\'re probably tired\\nOf hearing \\'bout my mom, oh-ho, whoa-ho\\nBut this is just a story of when I was just a shorty\\nAnd how I became hooked on Va-aliu-um\\nValium was in everything, food that I ate\\nThe water that I drank, fuckin\\' peas on my plate\\nShe sprinkled just enough of it to season my steak\\nSo every day I\\'d have at least three stomachaches\\nNow tell me, what kind of mother would want to see her\\nSon grow up to be an undera-fuckin\\'-chiever?\\nMy teacher didn\\'t think I was gonna be nothin\\' either\\n\"What the fuck you stickin\\' gum up under the fucking seat for?\"\\n\"Mrs. Mathers, your son has been huffing ether\\nEither that or the motherfucker\\'s been puffin\\' reefer\"\\nBut all this huffin\\' and puffin\\' wasn\\'t what it was either\\nIt was neither, I was buzzing but it wasn\\'t what she thought\\nPee in a teacup? Bitch, you ain\\'t my keeper, I\\'m sleeping\\nWhat the fuck you keep on fucking with me for?\\nSlut, you need to leave me the fuck alone, I ain\\'t playin\\'\\nGo find you a white crayon and color a fucking zebra\\n\\n[Chorus]\\nMy mom loved Valium and lots of drugs\\nThat\\'s why I am like I am \\'cause I\\'m like her\\nBecause my mom loved Valium and lots of drugs\\nThat\\'s why I\\'m on what I\\'m on \\'cause I\\'m my mom\\n\\n[Verse 2]\\nWait a minute, this ain\\'t dinner, this is paint thinner\\n\"You ate it yesterday, I ain\\'t hear no complaints, did I?\\nNow here\\'s a plate full of painkillers\\nNow just wait \\'til I crush the Valium and put it in your potatoes\\nYou little motherfucker, I\\'ll make you sit there and make\\nThat retarded fucking face without even tasting it\\nYou better lick the fucking plate, you ain\\'t wasting it\\nPut your face in it \\'fore I throw you in the basement again\\nAnd I ain\\'t givin\\' in, you\\'re gonna just sit there\\nIn one fucking place, finnickin\\' \\'til next Thanksgiving\\nAnd if you still ain\\'t finished it I\\'ll use the same shit again\\nThen when I make spinach dip it\\'ll be placed in the shit\\nYou little shit, wanna sit there and play innocent?\\nA rack fell and hit me in K-Mart and they witnessed it\\nChild support, your father, he ain\\'t sent the shit\\nAnd so what if he did? It\\'s none of your dang business, kid\"\\n\\n[Bridge 1]\\nMy mom\\nThere\\'s no one else quite like my mom\\nI know I should let bygones be bygones\\nBut she\\'s the reason why I am high what I\\'m high on\\n\\n[Chorus]\\n\\'Cause my mom loved Valium and lots of drugs\\nThat\\'s why I am like I am \\'cause I\\'m like her\\nBecause my mom loved Valium and lots of drugs\\nThat\\'s why I\\'m on what I\\'m on \\'cause I\\'m my mom\\n\\n[Bridge 2]\\nMy mom loved Valium, now all I am\\nIs a party animal, I am what I am\\nBut I\\'m strong to the finish with me Valium spinach\\nBut my buzz only lasts about two minutes\\nBut I don\\'t wanna swallow it without chewin\\' it\\nI can\\'t even write a rhyme without you in it\\nMy Valium, my Vaaaaaa-liummmm, ohh\\n\\n[Verse 3]\\nMan, I never thought that I could ever be\\nA drug addict, naw, fuck that, I can\\'t have it happen to me\\nBut that\\'s actually what has ended up happening\\nA tragedy, the fucking past ended up catching me\\nAnd it\\'s probably where I got acquainted with the taste, ain\\'t it?\\nPharmaceuticals are the bomb, Mom, beautiful\\nShe killed the fuckin\\' dog with the medicine she done fed it\\nFeed it a fuckin\\' aspirin and say that it has a headache\\n\"Here, want a snack? You hungry, you fuckin\\' brat?\\nLook at that, it\\'s a Xanax, take it and take a nap, eat it\"\\nBut I don\\'t need it \"Well fuck it then, break it up\\nTake a little piece and beat it before you wake Nathan up\"\\nAlright Ma, you win, I don\\'t feel like arguin\\'\\nI\\'ll do it, pop and gobble it and start wobblin\\'\\nStumble, hobble, tumble, slip, trip, then I fall in bed\\nWith a bottle of meds and a Heath Ledger bobblehead\\n\\n[Chorus]\\nMy mom loved Valium and lots of drugs\\nThat\\'s why I am like I am \\'cause I\\'m like her\\nBecause my mom loved Valium and lots of drugs\\nThat\\'s why I\\'m on what I\\'m on \\'cause I\\'m my mom\\n\\n[Outro]\\nMy mom, I\\'m just like her\\nMy mom, my mom, my mom\\nMy mom, my mom, my mom\\nMy mom, my mom, my mom\\nMy mom, my momma\\nMe momma, I like-a da momma\\nHaha, sorry Mom\\nI still love you though\\nDr. Dre, 2010\\nAy, this shit is hella hard, homie\\nYo, take us on outta here\\nWoo!'"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e6)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing Precision: {}'.format(precision_recall_fscore_support(y_test, y_pred, average='weighted')[0]))\n",
    "print('Testing Recall: {}'.format(precision_recall_fscore_support(y_test, y_pred, average='weighted')[1]))\n",
    "print('Testing FScore: {}'.format(precision_recall_fscore_support(y_test, y_pred, average='weighted')[2]))\n",
    "print('Testing Support: {}'.format(precision_recall_fscore_support(y_test, y_pred, average='weighted')[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class LyricsExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "#     def __init__(self, key=\"lyrics\"):\n",
    "#         self.key = key\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, train):\n",
    "        return train[\"lyrics\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LineCountExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        return data[\"lyrics\"].str.split(\"\\n\").apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AverageLineLengthExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        return data[\"lyrics\"].str.split(\"\\n\").apply(lambda lines: sum(map(len,lines))/len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniqueWordProportionExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        return data[\"lyrics\"].apply(lambda lyrics: self.prop_unique_words(lyrics))\n",
    "    \n",
    "    def prop_unique_words(self, lyrics):\n",
    "        return self.get_unique_word_count(lyrics) / self.get_total_word_count(lyrics)\n",
    "    \n",
    "    def get_total_word_count(self, lyrics):\n",
    "        return len(re.split(\" |\\n|\", lyrics))\n",
    "    \n",
    "    def get_unique_word_count(self, lyrics):\n",
    "        return len(set(re.split(\" |\\n|\", lyrics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ArrayCaster(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        return np.transpose(np.matrix(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "song_vect = Pipeline([\n",
    "                    (\"lyrics\", LyricsExtractor()),\n",
    "                    (\"tfidf\", TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS))\n",
    "                ])\n",
    "\n",
    "line_count = Pipeline([\n",
    "                    (\"get_line_count\", LineCountExtractor()),\n",
    "                    (\"caster\", ArrayCaster())\n",
    "                ])\n",
    "\n",
    "average_line_length = Pipeline([\n",
    "                    (\"get_average_line_length\", AverageLineLengthExtractor()),\n",
    "                    (\"caster\", ArrayCaster())\n",
    "                ])\n",
    "\n",
    "unique_word_proportion = Pipeline([\n",
    "                    (\"get_unique_word_proportion\", UniqueWordProportionExtractor()),\n",
    "                    (\"caster\", ArrayCaster())\n",
    "                ])\n",
    "\n",
    "featureunionvect = FeatureUnion([\n",
    "    (\"line_count\", line_count),\n",
    "    (\"song_vect\", song_vect),\n",
    "    (\"average_line_length\", average_line_length),\n",
    "    (\"unique_word_proportion\", unique_word_proportion)\n",
    "])\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "pipeline = Pipeline([('vect', featureunionvect), ('classifier', classifier)])\n",
    "\n",
    "# change these\n",
    "parameters = {\n",
    "    \"vect__song_vect__tfidf__max_df\": [0.7, 0.8, 1.0],\n",
    "    \"vect__song_vect__tfidf__min_df\": [1, 5, 20],\n",
    "    \"vect__transformer_weights\": [\n",
    "        # one feature only\n",
    "        {\"song_vectors\":0,\"line_count\":0, \"average_line_length\":0, \"unique_word_proportion\":1},#0001\n",
    "        {\"song_vectors\":0,\"line_count\":0, \"average_line_length\":1, \"unique_word_proportion\":0},#0010\n",
    "        {\"song_vectors\":0,\"line_count\":1, \"average_line_length\":0, \"unique_word_proportion\":0},#0100\n",
    "        {\"song_vectors\":1,\"line_count\":0, \"average_line_length\":0, \"unique_word_proportion\":0},#1000\n",
    "        \n",
    "        # two features\n",
    "        {\"song_vectors\":0,\"line_count\":0, \"average_line_length\":1, \"unique_word_proportion\":1},#0011\n",
    "        {\"song_vectors\":0,\"line_count\":1, \"average_line_length\":0, \"unique_word_proportion\":1},#0101\n",
    "        {\"song_vectors\":0,\"line_count\":1, \"average_line_length\":1, \"unique_word_proportion\":0},#0110\n",
    "        {\"song_vectors\":0,\"line_count\":0, \"average_line_length\":1, \"unique_word_proportion\":1},#1001\n",
    "        {\"song_vectors\":0,\"line_count\":0, \"average_line_length\":1, \"unique_word_proportion\":1},#1010\n",
    "        {\"song_vectors\":0,\"line_count\":0, \"average_line_length\":1, \"unique_word_proportion\":1},#1100\n",
    "        \n",
    "        # three features\n",
    "        {\"song_vectors\":0,\"line_count\":1, \"average_line_length\":1, \"unique_word_proportion\":1},#0111\n",
    "        {\"song_vectors\":1,\"line_count\":0, \"average_line_length\":1, \"unique_word_proportion\":1},#1011\n",
    "        {\"song_vectors\":1,\"line_count\":1, \"average_line_length\":0, \"unique_word_proportion\":1},#1101\n",
    "        {\"song_vectors\":1,\"line_count\":1, \"average_line_length\":1, \"unique_word_proportion\":0},#1110\n",
    "        \n",
    "        # all features\n",
    "        {\"song_vectors\":1,\"line_count\":1, \"average_line_length\": 1, \"unique_word_proportion\": 1},#1111\n",
    "    ],\n",
    "    \"classifier__C\": [1e5, 1e6, 1e7]\n",
    "}\n",
    "gs_clf = GridSearchCV(pipeline, parameters, cv=5)\n",
    "\n",
    "# dataset\n",
    "tracks_by_artist_copy = tracks_by_artist.copy()\n",
    "train, test = train_test_split(tracks_by_artist_copy, test_size=0.3, random_state=42)\n",
    "y_train, X_train = train[\"artist\"], train\n",
    "y_test, X_test = test[\"artist\"], test\n",
    "\n",
    "# classifier\n",
    "gs_clf.fit(X_train, y_train)\n",
    "\n",
    "#evaluation\n",
    "for score in gs_clf.grid_scores_:\n",
    "    print(\"gridsearch scores\", score)\n",
    "\n",
    "print(\"--------------------\")\n",
    "print(\"gridsearch best params\", gs_clf.best_params_)\n",
    "\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "# from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "# print('Testing Precision: {}'.format(precision_recall_fscore_support(y_test, y_pred, average='weighted')[0]))\n",
    "# print('Testing Recall: {}'.format(precision_recall_fscore_support(y_test, y_pred, average='weighted')[1]))\n",
    "# print('Testing FScore: {}'.format(precision_recall_fscore_support(y_test, y_pred, average='weighted')[2]))\n",
    "# print('Testing Support: {}'.format(precision_recall_fscore_support(y_test, y_pred, average='weighted')[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(y_train) # 475\n",
    "# len(X_train) #Â 475\n",
    "# len(y_test) # 204\n",
    "# len(X_test) # 204"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
