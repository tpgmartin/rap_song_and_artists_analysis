{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "* Create bags-of-words model\n",
    "* Remove stop words\n",
    "* Word clouds by artist by frequency, and by log-likelihood\n",
    "* TF-IDF to create weighted document vectors\n",
    "    * Ignore words that occur in less than 1% of songs\n",
    "    * Include bi-grams, tri-grams\n",
    "    * Do not stem or lemmatise words\n",
    "    * Colour actual song lyrics by TF-IDF ranking\n",
    "* Find cosine distance between artist vectors (vector sum of individual song vectors)\n",
    "* For each artist find most similar artists, most representative songs, most representative words\n",
    "* Hierarchical clustering of artists \n",
    "* Maybe: Latent semantic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracks_by_artist = pd.read_csv(\"./data/complete_tracks_with_lyrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_by_artist[\"word_list\"] = tracks_by_artist[\"word_list\"].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>track</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>word_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BROCKHAMPTON</td>\n",
       "      <td>iridescence</td>\n",
       "      <td>WEIGHT</td>\n",
       "      <td>[Verse 1: Kevin Abstact]\\nThey split my world ...</td>\n",
       "      <td>[they, split, my, world, into, pieces, i, ain'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BROCKHAMPTON</td>\n",
       "      <td>iridescence</td>\n",
       "      <td>VIVID</td>\n",
       "      <td>[Intro: Matt Champion]\\n\"Yo, get—[censored]—tu...</td>\n",
       "      <td>[yo, getcensoredturn, that, shit, over, boy, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BROCKHAMPTON</td>\n",
       "      <td>iridescence</td>\n",
       "      <td>TAPE</td>\n",
       "      <td>[Verse 1: Kevin Abstract]\\nI can barely rap, I...</td>\n",
       "      <td>[i, can, barely, rap, i, can, barely, dance, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BROCKHAMPTON</td>\n",
       "      <td>Saturation III</td>\n",
       "      <td>STAINS</td>\n",
       "      <td>[Verse 1: Ameer Vann]\\nI spent like a year and...</td>\n",
       "      <td>[i, spent, like, a, year, and, a, half, on, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BROCKHAMPTON</td>\n",
       "      <td>iridescence</td>\n",
       "      <td>DISTRICT</td>\n",
       "      <td>[Intro]\\n\"I'm Sammy Jo, and my favorite colors...</td>\n",
       "      <td>[i'm, sammy, jo, and, my, favorite, colors, ar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         artist           album     track  \\\n",
       "0  BROCKHAMPTON     iridescence    WEIGHT   \n",
       "1  BROCKHAMPTON     iridescence     VIVID   \n",
       "2  BROCKHAMPTON     iridescence      TAPE   \n",
       "3  BROCKHAMPTON  Saturation III    STAINS   \n",
       "4  BROCKHAMPTON     iridescence  DISTRICT   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  [Verse 1: Kevin Abstact]\\nThey split my world ...   \n",
       "1  [Intro: Matt Champion]\\n\"Yo, get—[censored]—tu...   \n",
       "2  [Verse 1: Kevin Abstract]\\nI can barely rap, I...   \n",
       "3  [Verse 1: Ameer Vann]\\nI spent like a year and...   \n",
       "4  [Intro]\\n\"I'm Sammy Jo, and my favorite colors...   \n",
       "\n",
       "                                           word_list  \n",
       "0  [they, split, my, world, into, pieces, i, ain'...  \n",
       "1  [yo, getcensoredturn, that, shit, over, boy, c...  \n",
       "2  [i, can, barely, rap, i, can, barely, dance, i...  \n",
       "3  [i, spent, like, a, year, and, a, half, on, th...  \n",
       "4  [i'm, sammy, jo, and, my, favorite, colors, ar...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_by_artist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8674\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i in range(20):\n",
    "    total += len(tracks_by_artist.iloc[i][\"word_list\"])\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectoriser = TfidfVectorizer(\n",
    "    stop_words=ENGLISH_STOP_WORDS,\n",
    "#   lowercase=True,\n",
    "    ngram_range=(1,3),\n",
    "#   tokenizer=don't specify tokenizer for now,\n",
    "    norm=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_by_artists = tracks_by_artist.groupby(\"artist\", as_index=False)[\"word_list\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>word_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BROCKHAMPTON</td>\n",
       "      <td>[they, split, my, world, into, pieces, i, ain'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drake</td>\n",
       "      <td>[i, been, waitin', on, this, yeah, all, of, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eminem</td>\n",
       "      <td>[yeah, it's, my, life, in, my, own, words, i, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Future</td>\n",
       "      <td>[wake, up, tryna, make, motherfuckin', hits, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gucci Mane</td>\n",
       "      <td>[murda, on, the, beat, so, it's, not, nice, ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>J. Cole</td>\n",
       "      <td>[oh, right, oh, oh, why, nadadada, i, keep, my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kendrick Lamar</td>\n",
       "      <td>[everything, black, i, don't, want, black, i, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kevin Gates</td>\n",
       "      <td>[oooh, ooh, ooh, you, had, to, you, had, to, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kodak Black</td>\n",
       "      <td>[glee, sniper, gang, glee, i'm, coolin', but, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lil Uzi Vert</td>\n",
       "      <td>[can't, nobody, touch, my, swag, can't, nobody...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lil Yachty</td>\n",
       "      <td>[ayy, ooh, ayy, i'm, on, some, other, shit, oo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Migos</td>\n",
       "      <td>[ooh, yeah, yeah, culture, culture, culture, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Moneybagg Yo</td>\n",
       "      <td>[uh, it's, like, a, scary, sight, or, somethin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NF</td>\n",
       "      <td>[i, heard, you, told, your, friends, that, i'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Post Malone</td>\n",
       "      <td>[yeah, yeah, yeah, yeah, i, know, my, wrist, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Russ</td>\n",
       "      <td>[i, wanna, go, down, with, you, baby, yeah, ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>[got, you, rolling, papers, got, you, rolling,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>YoungBoy Never Broke Again</td>\n",
       "      <td>[you, know, im, a, real, nigga, you, might, as...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        artist  \\\n",
       "0                 BROCKHAMPTON   \n",
       "1                        Drake   \n",
       "2                       Eminem   \n",
       "3                       Future   \n",
       "4                   Gucci Mane   \n",
       "5                      J. Cole   \n",
       "6               Kendrick Lamar   \n",
       "7                  Kevin Gates   \n",
       "8                  Kodak Black   \n",
       "9                 Lil Uzi Vert   \n",
       "10                  Lil Yachty   \n",
       "11                       Migos   \n",
       "12                Moneybagg Yo   \n",
       "13                          NF   \n",
       "14                 Post Malone   \n",
       "15                        Russ   \n",
       "16                 Wiz Khalifa   \n",
       "17  YoungBoy Never Broke Again   \n",
       "\n",
       "                                            word_list  \n",
       "0   [they, split, my, world, into, pieces, i, ain'...  \n",
       "1   [i, been, waitin', on, this, yeah, all, of, th...  \n",
       "2   [yeah, it's, my, life, in, my, own, words, i, ...  \n",
       "3   [wake, up, tryna, make, motherfuckin', hits, n...  \n",
       "4   [murda, on, the, beat, so, it's, not, nice, ha...  \n",
       "5   [oh, right, oh, oh, why, nadadada, i, keep, my...  \n",
       "6   [everything, black, i, don't, want, black, i, ...  \n",
       "7   [oooh, ooh, ooh, you, had, to, you, had, to, k...  \n",
       "8   [glee, sniper, gang, glee, i'm, coolin', but, ...  \n",
       "9   [can't, nobody, touch, my, swag, can't, nobody...  \n",
       "10  [ayy, ooh, ayy, i'm, on, some, other, shit, oo...  \n",
       "11  [ooh, yeah, yeah, culture, culture, culture, c...  \n",
       "12  [uh, it's, like, a, scary, sight, or, somethin...  \n",
       "13  [i, heard, you, told, your, friends, that, i'm...  \n",
       "14  [yeah, yeah, yeah, yeah, i, know, my, wrist, b...  \n",
       "15  [i, wanna, go, down, with, you, baby, yeah, ye...  \n",
       "16  [got, you, rolling, papers, got, you, rolling,...  \n",
       "17  [you, know, im, a, real, nigga, you, might, as...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_by_artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-25004f726dd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectoriser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlyrics_by_artists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"word_list\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1379\u001b[0m             \u001b[0mTf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \"\"\"\n\u001b[0;32m-> 1381\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1382\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 869\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 266\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "list(vectoriser.fit_transform(lyrics_by_artists[\"word_list\"].values).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
